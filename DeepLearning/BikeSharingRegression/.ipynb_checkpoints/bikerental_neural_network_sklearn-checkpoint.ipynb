{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Regression using SKLearn's Neural Network (NN)\n",
    "#### One-Hot Encode categorical features, Standardize numeric features\n",
    "\n",
    "Objective:\n",
    "1. Train a bike rental prediction model\n",
    "2. NN requires one hot encoding of categorical data\n",
    "3. NN also requires features to be on similar scale\n",
    "4. Perform one-hot encoding of all categorical features:\n",
    "    ['season', 'holiday', 'workingday', 'weather', 'year', 'month', 'day', 'dayofweek', 'hour']\n",
    "5. Verify model performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "# Set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# NN\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, KBinsDiscretizer\n",
    "# Column Transformer\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list_file = 'bike_train_column_list.txt'\n",
    "train_file = 'bike_train.csv'\n",
    "validation_file = 'bike_validation.csv'\n",
    "test_file = 'bike_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode all Categorical Features\n",
    "# Let's define all the categorical features\n",
    "categorical_features = ['season','holiday','workingday','weather','year','month','dayofweek','hour']\n",
    "\n",
    "# Standardize Features\n",
    "standardize_features = ['temp', 'atemp', 'humidity', 'windspeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ''\n",
    "with open(column_list_file,'r') as f:\n",
    "    columns = f.read().split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the column names as the file does not have column header\n",
    "df_train = pd.read_csv(train_file,names=columns)\n",
    "df_validation = pd.read_csv(validation_file,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:,1:] # Features: 1st column onwards \n",
    "y_train = df_train.iloc[:,0].ravel() # Target: 0th column\n",
    "\n",
    "X_validation = df_validation.iloc[:,1:]\n",
    "y_validation = df_validation.iloc[:,0].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to one-hot encode\n",
    "categorical_features+['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to standardize\n",
    "standardize_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Transformer\n",
    "1. Chain all data transformations\n",
    "2. Easy and straight forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colTransformer = ColumnTransformer([('onehot',\n",
    "                                     OneHotEncoder(categories='auto',sparse=False),\n",
    "                                     categorical_features),\n",
    "                                    ('onehotday',\n",
    "                                     OneHotEncoder(categories=[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]],\n",
    "                                                   sparse=False),\n",
    "                                     ['day']),\n",
    "                                    ('standardize',\n",
    "                                    StandardScaler(),standardize_features)\n",
    "                                   ],\n",
    "                                   remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colTransformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = colTransformer.transform(X_train)\n",
    "X_validation_encoded = colTransformer.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Data',X_train.shape, 'OneHot Encoded',X_train_encoded.shape)\n",
    "print('Val Data',X_validation.shape, 'OneHot Encoded',X_validation_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation_encoded[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a neural network regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_regressor = MLPRegressor(random_state=5, \n",
    "                            hidden_layer_sizes=[100],\n",
    "                            activation='relu',\n",
    "                            max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nn_regressor.fit(X_train_encoded,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare actual vs predicted performance with dataset not seen by the model before\n",
    "df = pd.read_csv(validation_file,names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = nn_regressor.predict(X_validation_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_predicted'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_predicted'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert log(count) to count\n",
    "df['count'] = df['count'].map(np.expm1)\n",
    "df['count_predicted'] = df['count_predicted'].map(np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual Vs Predicted\n",
    "plt.plot(df['count'], label='Actual')\n",
    "plt.plot(df['count_predicted'],label='Predicted')\n",
    "plt.xlabel('Sample')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim([100,150])\n",
    "plt.title('Validation Dataset - Predicted Vs. Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over prediction and Under Prediction needs to be balanced\n",
    "# Training Data Residuals\n",
    "residuals = (df['count'] - df['count_predicted'])\n",
    "\n",
    "plt.hist(residuals)\n",
    "plt.grid(True)\n",
    "plt.xlabel('Actual - Predicted')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.axvline(color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = (residuals > 0).value_counts(sort=False)\n",
    "print(' Under Estimation: {0:.2f}'.format(value_counts[True]/len(residuals)))\n",
    "print(' Over  Estimation: {0:.2f}'.format(value_counts[False]/len(residuals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "print(\"RMSE: {0:.2f}\".format(metrics.mean_squared_error(df['count'],\n",
    "                                                    df['count_predicted'])**.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Use By Kaggle\n",
    "def compute_rmsle(y_true, y_pred):\n",
    "    if type(y_true) != np.ndarray:\n",
    "        y_true = np.array(y_true)\n",
    "        \n",
    "    if type(y_pred) != np.ndarray:\n",
    "        y_pred = np.array(y_pred)\n",
    "     \n",
    "    return(np.average((np.log1p(y_pred) - np.log1p(y_true))**2)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSLE: {0:.2f}\".format(compute_rmsle(df['count'],df['count_predicted'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Test Data\n",
    "# Prepare Data for Submission to Kaggle\n",
    "df_test = pd.read_csv(test_file,parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  df_test.iloc[:,1:] # Exclude datetime for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data first with column transformer\n",
    "result = nn_regressor.predict(colTransformer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert result to actual count\n",
    "df_test[\"count\"] = np.expm1(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test[\"count\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['datetime','count']].to_csv('predicted_count.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
